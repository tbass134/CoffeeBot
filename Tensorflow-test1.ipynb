{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Image\n",
    "from pandas import get_dummies\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Config the matlotlib backend as plotting inline in IPython\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clouds</th>\n",
       "      <th>humidity</th>\n",
       "      <th>temp</th>\n",
       "      <th>type</th>\n",
       "      <th>visibility</th>\n",
       "      <th>windSpeed</th>\n",
       "      <th>weatherCond_Clear</th>\n",
       "      <th>weatherCond_Clouds</th>\n",
       "      <th>weatherCond_Fog</th>\n",
       "      <th>weatherCond_Haze</th>\n",
       "      <th>weatherCond_Rain</th>\n",
       "      <th>weatherCond_Smoke</th>\n",
       "      <th>weatherCond_Snow</th>\n",
       "      <th>weatherCond_Thunderstorm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FFB69BDF-D8CC-4E12-A944-3AC7FB582383</th>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B21714A4-BD63-4BA2-9296-65C466681513</th>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1E8A0181-D13B-469B-AA49-DA16EFF6C227</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C1E16B18-8396-4031-A312-22C70D405C6C</th>\n",
       "      <td>75</td>\n",
       "      <td>80</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C0784390-B4F3-49A4-8E99-2CB8A4D6FE51</th>\n",
       "      <td>90</td>\n",
       "      <td>82</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      clouds  humidity  temp  type  \\\n",
       "FFB69BDF-D8CC-4E12-A944-3AC7FB582383       1        45  81.0     0   \n",
       "B21714A4-BD63-4BA2-9296-65C466681513       1        83  70.0     0   \n",
       "1E8A0181-D13B-469B-AA49-DA16EFF6C227       1        33  73.0     0   \n",
       "C1E16B18-8396-4031-A312-22C70D405C6C      75        80  39.0     0   \n",
       "C0784390-B4F3-49A4-8E99-2CB8A4D6FE51      90        82  70.0     0   \n",
       "\n",
       "                                      visibility  windSpeed  \\\n",
       "FFB69BDF-D8CC-4E12-A944-3AC7FB582383        10.0        3.0   \n",
       "B21714A4-BD63-4BA2-9296-65C466681513        10.0        2.0   \n",
       "1E8A0181-D13B-469B-AA49-DA16EFF6C227        10.0        9.0   \n",
       "C1E16B18-8396-4031-A312-22C70D405C6C        10.0       12.0   \n",
       "C0784390-B4F3-49A4-8E99-2CB8A4D6FE51        10.0        9.0   \n",
       "\n",
       "                                      weatherCond_Clear  weatherCond_Clouds  \\\n",
       "FFB69BDF-D8CC-4E12-A944-3AC7FB582383                  1                   0   \n",
       "B21714A4-BD63-4BA2-9296-65C466681513                  1                   0   \n",
       "1E8A0181-D13B-469B-AA49-DA16EFF6C227                  1                   0   \n",
       "C1E16B18-8396-4031-A312-22C70D405C6C                  0                   1   \n",
       "C0784390-B4F3-49A4-8E99-2CB8A4D6FE51                  0                   1   \n",
       "\n",
       "                                      weatherCond_Fog  weatherCond_Haze  \\\n",
       "FFB69BDF-D8CC-4E12-A944-3AC7FB582383                0                 0   \n",
       "B21714A4-BD63-4BA2-9296-65C466681513                0                 0   \n",
       "1E8A0181-D13B-469B-AA49-DA16EFF6C227                0                 0   \n",
       "C1E16B18-8396-4031-A312-22C70D405C6C                0                 0   \n",
       "C0784390-B4F3-49A4-8E99-2CB8A4D6FE51                0                 0   \n",
       "\n",
       "                                      weatherCond_Rain  weatherCond_Smoke  \\\n",
       "FFB69BDF-D8CC-4E12-A944-3AC7FB582383                 0                  0   \n",
       "B21714A4-BD63-4BA2-9296-65C466681513                 0                  0   \n",
       "1E8A0181-D13B-469B-AA49-DA16EFF6C227                 0                  0   \n",
       "C1E16B18-8396-4031-A312-22C70D405C6C                 0                  0   \n",
       "C0784390-B4F3-49A4-8E99-2CB8A4D6FE51                 0                  0   \n",
       "\n",
       "                                      weatherCond_Snow  \\\n",
       "FFB69BDF-D8CC-4E12-A944-3AC7FB582383                 0   \n",
       "B21714A4-BD63-4BA2-9296-65C466681513                 0   \n",
       "1E8A0181-D13B-469B-AA49-DA16EFF6C227                 0   \n",
       "C1E16B18-8396-4031-A312-22C70D405C6C                 0   \n",
       "C0784390-B4F3-49A4-8E99-2CB8A4D6FE51                 0   \n",
       "\n",
       "                                      weatherCond_Thunderstorm  \n",
       "FFB69BDF-D8CC-4E12-A944-3AC7FB582383                         0  \n",
       "B21714A4-BD63-4BA2-9296-65C466681513                         0  \n",
       "1E8A0181-D13B-469B-AA49-DA16EFF6C227                         0  \n",
       "C1E16B18-8396-4031-A312-22C70D405C6C                         0  \n",
       "C0784390-B4F3-49A4-8E99-2CB8A4D6FE51                         0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('coffeeBotData-Cleaned.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['clouds', 'humidity', 'temp', 'visibility', 'windSpeed',\n",
      "       'weatherCond_Clear', 'weatherCond_Clouds', 'weatherCond_Fog',\n",
      "       'weatherCond_Haze', 'weatherCond_Rain', 'weatherCond_Smoke',\n",
      "       'weatherCond_Snow', 'weatherCond_Thunderstorm'],\n",
      "      dtype='object')\n",
      "type\n"
     ]
    }
   ],
   "source": [
    "#move type to back\n",
    "df1 = df.pop('type')\n",
    "df['type']=df1\n",
    "\n",
    "cols = df.columns\n",
    "features = cols[0:-1]\n",
    "labels = cols[-1]\n",
    "print(features)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averages\n",
      "clouds                      7.612429e-16\n",
      "humidity                   -2.893981e-16\n",
      "temp                       -2.026157e-16\n",
      "visibility                 -1.404432e-16\n",
      "windSpeed                  -2.331468e-16\n",
      "weatherCond_Clear          -2.509104e-16\n",
      "weatherCond_Clouds         -5.662137e-17\n",
      "weatherCond_Fog             6.232052e-16\n",
      "weatherCond_Haze            2.235249e-16\n",
      "weatherCond_Rain            2.335169e-16\n",
      "weatherCond_Smoke           4.880355e-18\n",
      "weatherCond_Snow            3.892719e-16\n",
      "weatherCond_Thunderstorm    1.113924e-16\n",
      "type                        5.000000e-01\n",
      "dtype: float64\n",
      "\n",
      " Deviations\n",
      "clouds                      1.000000\n",
      "humidity                    1.000000\n",
      "temp                        1.000000\n",
      "visibility                  1.000000\n",
      "windSpeed                   1.000000\n",
      "weatherCond_Clear           1.000000\n",
      "weatherCond_Clouds          1.000000\n",
      "weatherCond_Fog             1.000000\n",
      "weatherCond_Haze            1.000000\n",
      "weatherCond_Rain            1.000000\n",
      "weatherCond_Smoke           1.000000\n",
      "weatherCond_Snow            1.000000\n",
      "weatherCond_Thunderstorm    1.000000\n",
      "type                        0.250417\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Well conditioned data will have zero mean and equal variance\n",
    "#We get this automattically when we calculate the Z Scores for the data\n",
    "\n",
    "data_norm = pd.DataFrame(df)\n",
    "\n",
    "for feature in features:\n",
    "    df[feature] = (df[feature] - df[feature].mean())/df[feature].std()\n",
    "\n",
    "#Show that should now have zero mean\n",
    "print(\"Averages\")\n",
    "print(df.mean())\n",
    "\n",
    "print(\"\\n Deviations\")\n",
    "#Show that we have equal variance\n",
    "print(pow(df.std(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Shuffle The data\n",
    "indices = data_norm.index.tolist()\n",
    "indices = np.array(indices)\n",
    "np.random.shuffle(indices)\n",
    "X = data_norm.reindex(indices)[features]\n",
    "y = data_norm.reindex(indices)[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One Hot Encode as a dataframe\n",
    "y = get_dummies(y)\n",
    "\n",
    "# Generate Training and Validation Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Convert to np arrays so that we can use with TensorFlow\n",
    "X_train = np.array(X_train).astype(np.float32)\n",
    "X_test  = np.array(X_test).astype(np.float32)\n",
    "y_train = np.array(y_train).astype(np.float32)\n",
    "y_test  = np.array(y_test).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(402, 13) (402, 2)\n",
      "(198, 13) (198, 2)\n"
     ]
    }
   ],
   "source": [
    "#Check to make sure split still has 4 features and 3 labels\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(402, 13), dtype=float32)\n",
      "Tensor(\"Const_1:0\", shape=(402, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "training_size = X_train.shape[1]\n",
    "test_size = X_test.shape[1]\n",
    "num_features = 13\n",
    "num_labels = 2\n",
    "\n",
    "\n",
    "num_hidden = 10\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    tf_train_set    = tf.constant(X_train)\n",
    "    tf_train_labels = tf.constant(y_train)\n",
    "    tf_valid_set    = tf.constant(X_test)\n",
    " \n",
    "    \n",
    "    print(tf_train_set)\n",
    "    print(tf_train_labels)\n",
    "    \n",
    "    ## Note, since there is only 1 layer there are actually no hidden layers... but if there were\n",
    "    ## there would be num_hidden\n",
    "    weights_1 = tf.Variable(tf.truncated_normal([num_features, num_hidden], name=\"weights_1\"))\n",
    "    weights_2 = tf.Variable(tf.truncated_normal([num_hidden, num_labels], name=\"weights_2\"))\n",
    "    ## tf.zeros Automaticaly adjusts rows to input data batch size\n",
    "    bias_1 = tf.Variable(tf.zeros([num_hidden], name=\"bias_1\"))\n",
    "    bias_2 = tf.Variable(tf.zeros([num_labels], name=\"bias_2\"))\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "    \n",
    "    logits_1 = tf.matmul(tf_train_set , weights_1, name=\"logits_1\" ) + bias_1\n",
    "    rel_1 = tf.nn.relu(logits_1, name=\"rel_1\")\n",
    "    logits_2 = tf.matmul(rel_1, weights_2, name=\"logits_2\") + bias_2\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits_2, labels=tf_train_labels))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(.1).minimize(loss)\n",
    "    \n",
    "    \n",
    "    ## Training prediction\n",
    "    predict_train = tf.nn.softmax(logits_2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Validation prediction\n",
    "    logits_1_val = tf.matmul(tf_valid_set, weights_1) + bias_1\n",
    "    rel_1_val    = tf.nn.relu(logits_1_val)\n",
    "    logits_2_val = tf.matmul(rel_1_val, weights_2) + bias_2\n",
    "    predict_valid = tf.nn.softmax(logits_2_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.278749\n",
      "Loss at step 0: 2.278749\n",
      "Training accuracy: 51.2%\n",
      "Validation accuracy: 51.5%\n",
      "Model saved in path: /tmp/model.ckpt\n",
      "Loss at step 2000: 0.420242\n",
      "Training accuracy: 80.6%\n",
      "Validation accuracy: 72.7%\n",
      "Model saved in path: /tmp/model.ckpt\n",
      "Loss at step 4000: 0.393381\n",
      "Training accuracy: 82.6%\n",
      "Validation accuracy: 71.7%\n",
      "Model saved in path: /tmp/model.ckpt\n",
      "Loss at step 6000: 0.370464\n",
      "Training accuracy: 84.6%\n",
      "Validation accuracy: 71.7%\n",
      "Model saved in path: /tmp/model.ckpt\n",
      "Loss at step 8000: 0.358558\n",
      "Training accuracy: 83.3%\n",
      "Validation accuracy: 73.2%\n",
      "Model saved in path: /tmp/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "num_steps = 10000\n",
    "with tf.Session(graph = graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(loss.eval())\n",
    "    for step in range(num_steps):\n",
    "        _,l, predictions = session.run([optimizer, loss, predict_train])\n",
    "        \n",
    "        if (step % 2000 == 0):\n",
    "            #print(predictions[3:6])\n",
    "            print('Loss at step %d: %f' % (step, l))\n",
    "            print('Training accuracy: %.1f%%' % accuracy( predictions, y_train[:, :]))\n",
    "            print('Validation accuracy: %.1f%%' % accuracy(predict_valid.eval(), y_test))\n",
    "            save_path = saver.save(session, \"/tmp/model.ckpt\")\n",
    "            print(\"Model saved in path: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: saved_model.pb\n"
     ]
    }
   ],
   "source": [
    " tf.saved_model.simple_save(session,\n",
    "    \"\",inputs={\n",
    "        \"weights_1\": weights_1,\n",
    "        \"weights_2\": weights_2,\n",
    "        \"bias_1\":bias_1,\n",
    "        \"bias_2\":bias_2\n",
    "    },outputs={\n",
    "        \"logits_1\": logits_1,\n",
    "         \"rel_1\":rel_1,\n",
    "         \"logits_2\":logits_2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoint = tf.train.get_checkpoint_state(\"/tmp/\")\n",
    "input_checkpoint = checkpoint.model_checkpoint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflowjs\n",
      "  Downloading https://files.pythonhosted.org/packages/43/b2/d09672c18d6bbaa7105f74f11f6f88f0dadbce6ea0691a4509b234c16a2c/tensorflowjs-0.6.4-py3-none-any.whl\n",
      "Collecting numpy==1.15.1 (from tensorflowjs)\n",
      "  Downloading https://files.pythonhosted.org/packages/8b/5f/a7765a144fd788135a5cad90bf4c144df3b6c3343a08fff4ff8f98217641/numpy-1.15.1-cp35-cp35m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (24.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 24.4MB 52kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting six==1.11.0 (from tensorflowjs)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Using cached https://files.pythonhosted.org/packages/67/4b/141a581104b1f6397bfa78ac9d43d8ad29a7ca43ea90a2d863fe3056e86a/six-1.11.0-py2.py3-none-any.whl\n",
      "Collecting keras==2.2.2 (from tensorflowjs)\n",
      "  Downloading https://files.pythonhosted.org/packages/34/7d/b1dedde8af99bd82f20ed7e9697aac0597de3049b1f786aa2aac3b9bd4da/Keras-2.2.2-py2.py3-none-any.whl (299kB)\n",
      "\u001b[K    100% |████████████████████████████████| 307kB 3.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting h5py==2.8.0 (from tensorflowjs)\n",
      "  Downloading https://files.pythonhosted.org/packages/ba/5e/88e9bdd1c832624df36b240068a2389d4d1876de84412783c878338b4275/h5py-2.8.0-cp35-cp35m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (6.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 6.1MB 245kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-hub==0.1.1 (from tensorflowjs)\n",
      "  Downloading https://files.pythonhosted.org/packages/5f/22/64f246ef80e64b1a13b2f463cefa44f397a51c49a303294f5f3d04ac39ac/tensorflow_hub-0.1.1-py2.py3-none-any.whl (52kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 5.6MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow==1.11.0 (from tensorflowjs)\n",
      "  Downloading https://files.pythonhosted.org/packages/af/f5/e4e633626e55afab3d77d0c7e2fe0cc7073a102263b16f8cbfea8c54b743/tensorflow-1.11.0-cp35-cp35m-macosx_10_11_x86_64.whl (59.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 59.4MB 22kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.14 in /Users/antoniohung/anaconda/envs/tensorflow/lib/python3.5/site-packages (from keras==2.2.2->tensorflowjs)\n",
      "Collecting keras-preprocessing==1.0.2 (from keras==2.2.2->tensorflowjs)\n",
      "  Downloading https://files.pythonhosted.org/packages/71/26/1e778ebd737032749824d5cba7dbd3b0cf9234b87ab5ec79f5f0403ca7e9/Keras_Preprocessing-1.0.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pyyaml in /Users/antoniohung/anaconda/envs/tensorflow/lib/python3.5/site-packages (from keras==2.2.2->tensorflowjs)\n",
      "Collecting keras-applications==1.0.4 (from keras==2.2.2->tensorflowjs)\n",
      "  Downloading https://files.pythonhosted.org/packages/54/90/8f327deaa37a71caddb59b7b4aaa9d4b3e90c0e76f8c2d1572005278ddc5/Keras_Applications-1.0.4-py2.py3-none-any.whl (43kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 8.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.4.0 in /Users/antoniohung/anaconda/envs/tensorflow/lib/python3.5/site-packages (from tensorflow-hub==0.1.1->tensorflowjs)\n",
      "Requirement already satisfied: setuptools<=39.1.0 in /Users/antoniohung/anaconda/envs/tensorflow/lib/python3.5/site-packages/setuptools-27.2.0-py3.5.egg (from tensorflow==1.11.0->tensorflowjs)\n",
      "Collecting tensorboard<1.12.0,>=1.11.0 (from tensorflow==1.11.0->tensorflowjs)\n",
      "  Downloading https://files.pythonhosted.org/packages/9b/2f/4d788919b1feef04624d63ed6ea45a49d1d1c834199ec50716edb5d310f4/tensorboard-1.11.0-py3-none-any.whl (3.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.0MB 448kB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /Users/antoniohung/anaconda/envs/tensorflow/lib/python3.5/site-packages (from tensorflow==1.11.0->tensorflowjs)\n",
      "Requirement already satisfied: astor>=0.6.0 in /Users/antoniohung/anaconda/envs/tensorflow/lib/python3.5/site-packages (from tensorflow==1.11.0->tensorflowjs)\n",
      "Requirement already satisfied: gast>=0.2.0 in /Users/antoniohung/anaconda/envs/tensorflow/lib/python3.5/site-packages (from tensorflow==1.11.0->tensorflowjs)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/antoniohung/anaconda/envs/tensorflow/lib/python3.5/site-packages (from tensorflow==1.11.0->tensorflowjs)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /Users/antoniohung/anaconda/envs/tensorflow/lib/python3.5/site-packages (from tensorflow==1.11.0->tensorflowjs)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/antoniohung/anaconda/envs/tensorflow/lib/python3.5/site-packages (from tensorflow==1.11.0->tensorflowjs)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /Users/antoniohung/anaconda/envs/tensorflow/lib/python3.5/site-packages (from tensorboard<1.12.0,>=1.11.0->tensorflow==1.11.0->tensorflowjs)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/antoniohung/anaconda/envs/tensorflow/lib/python3.5/site-packages (from tensorboard<1.12.0,>=1.11.0->tensorflow==1.11.0->tensorflowjs)\n",
      "Installing collected packages: numpy, six, h5py, keras-preprocessing, keras-applications, keras, tensorflow-hub, tensorboard, tensorflow, tensorflowjs\n",
      "  Found existing installation: numpy 1.14.2\n",
      "    Uninstalling numpy-1.14.2:\n",
      "      Successfully uninstalled numpy-1.14.2\n",
      "  Found existing installation: six 1.10.0\n",
      "\u001b[31m    DEPRECATION: Uninstalling a distutils installed project (six) has been deprecated and will be removed in a future version. This is due to the fact that uninstalling a distutils project will only partially uninstall the project.\u001b[0m\n",
      "    Uninstalling six-1.10.0:\n",
      "      Successfully uninstalled six-1.10.0\n",
      "  Found existing installation: tensorboard 1.10.0\n",
      "    Uninstalling tensorboard-1.10.0:\n",
      "      Successfully uninstalled tensorboard-1.10.0\n",
      "  Found existing installation: tensorflow 1.10.0\n",
      "    Uninstalling tensorflow-1.10.0:\n",
      "      Successfully uninstalled tensorflow-1.10.0\n",
      "Successfully installed h5py-2.8.0 keras-2.2.2 keras-applications-1.0.4 keras-preprocessing-1.0.2 numpy-1.15.1 six-1.11.0 tensorboard-1.11.0 tensorflow-1.11.0 tensorflow-hub-0.1.1 tensorflowjs-0.6.4\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorflowjs_converter \\\n",
    "    --input_format=tf_frozen_model \\\n",
    "    --output_node_names='model' \\\n",
    "    --saved_model_tags=serve \\\n",
    "    /saved_model.pb \\\n",
    "    /\"my_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "simple_save() missing 3 required positional arguments: 'export_dir', 'inputs', and 'outputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-48b135e400c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimple_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: simple_save() missing 3 required positional arguments: 'export_dir', 'inputs', and 'outputs'"
     ]
    }
   ],
   "source": [
    "tf.saved_model.simple_save(session, export_dir=\"/\", )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
